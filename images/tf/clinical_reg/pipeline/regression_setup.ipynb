{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pipelines SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please wait till this cell completes and then run next cells. This just need to be run once per active kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: RELEASE_VERSION=1.0.0\n",
      "Collecting https://storage.googleapis.com/ml-pipeline/release/1.0.0/kfp.tar.gz\n",
      "  Using cached https://storage.googleapis.com/ml-pipeline/release/1.0.0/kfp.tar.gz (122 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (5.3.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.33.0)\n",
      "Requirement already satisfied: kubernetes<12.0.0,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (11.0.0)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.23.0)\n",
      "Requirement already satisfied: requests_toolbelt>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (0.9.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.6.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (3.2.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (0.8.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (7.1.2)\n",
      "Requirement already satisfied: Deprecated in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.2.10)\n",
      "Requirement already satisfied: strip-hints in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (0.1.9)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated->kfp==1.0.0) (1.12.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (4.6)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (49.6.0.post20201009)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (4.1.1)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.23.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (1.4.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (2.25.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.0.0) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (49.6.0.post20201009)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.0.0) (3.14.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.0.0) (2020.4)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.23.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (2.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.0.0) (1.52.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==1.0.0) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==1.0.0) (2.20)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.0.0) (3.14.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==1.0.0) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==1.0.0) (20.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (49.6.0.post20201009)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp==1.0.0) (3.4.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (2.8.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (2020.11.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (5.3.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (49.6.0.post20201009)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (2.25.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (1.25.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (2020.11.8)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.0) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (2.8.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.0.0) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==1.0.0) (0.4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==1.0.0) (2.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==1.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.0) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp==1.0.0) (3.0.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (2.25.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==1.0.0) (2.25.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==1.0.0) (0.4.8)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints->kfp==1.0.0) (0.36.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.0) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "%env RELEASE_VERSION=1.0.0\n",
    "!pip install https://storage.googleapis.com/ml-pipeline/release/${RELEASE_VERSION}/kfp.tar.gz --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import kfp pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define e2e regression Pipeline with Dkube components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kfp.components._yaml_utils import load_yaml\n",
    "from kfp.components._yaml_utils import dump_yaml\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import os\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "def _component(stage, name):\n",
    "    with open('../components/{}/component.yaml'.format(stage), 'rb') as stream:\n",
    "        cdict = load_yaml(stream)\n",
    "        cdict['name'] = name\n",
    "        cyaml = dump_yaml(cdict)\n",
    "        return components.load_component_from_text(cyaml)\n",
    "        \n",
    "#dkube_preprocess_op         = components.load_component_from_file(\"../components/preprocess/component.yaml\")\n",
    "#dkube_training_op           = components.load_component_from_file(\"../components/training/component.yaml\")\n",
    "#dkube_serving_op            = components.load_component_from_file(\"../components/serving/component.yaml\")\n",
    "#dkube_viewer_op             = components.load_component_from_file('../components/viewer/component.yaml')\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='dkube-regression-pl',\n",
    "    description='sample regression pipeline with dkube components'\n",
    ")\n",
    "\n",
    "def d3pipeline(\n",
    "    access_url,\n",
    "    user,\n",
    "    auth_token,\n",
    "    #Clinical preprocess\n",
    "    clinical_preprocess_script=\"python cli-pre-processing.py\",\n",
    "    clinical_preprocess_datasets=json.dumps([\"clinical\"]),\n",
    "    clinical_preprocess_input_mounts=json.dumps([\"/opt/dkube/input\"]),\n",
    "    clinical_preprocess_outputs=json.dumps([\"clinical-preprocessed\"]),\n",
    "    clinical_preprocess_output_mounts=json.dumps([\"/opt/dkube/output\"]),\n",
    "    \n",
    "    #Image preprocess\n",
    "    image_preprocess_script=\"python img-pre-processing.py\",\n",
    "    image_preprocess_datasets=json.dumps([\"images\"]),\n",
    "    image_preprocess_input_mounts=json.dumps([\"/opt/dkube/input\"]),\n",
    "    image_preprocess_outputs=json.dumps([\"images-preprocessed\"]),\n",
    "    image_preprocess_output_mounts=json.dumps([\"/opt/dkube/output\"]),\n",
    "    \n",
    "    #Clinical split\n",
    "    clinical_split_script=\"python split.py --datatype clinical\",\n",
    "    clinical_split_datasets=json.dumps([\"clinical-preprocessed\"]),\n",
    "    clinical_split_input_mounts=json.dumps([\"/opt/dkube/input\"]),\n",
    "    clinical_split_outputs=json.dumps([\"clinical-train\", \"clinical-test\", \"clinical-val\"]),\n",
    "    clinical_split_output_mounts=json.dumps([\"/opt/dkube/outputs/train\", \"/opt/dkube/outputs/test\", \"/opt/dkube/outputs/val\"]),\n",
    "    \n",
    "    #Image split\n",
    "    image_split_script=\"python split.py --datatype image\",\n",
    "    image_split_datasets=json.dumps([\"images-preprocessed\"]),\n",
    "    image_split_input_mounts=json.dumps([\"/opt/dkube/input\"]),\n",
    "    image_split_outputs=json.dumps([\"images-train\", \"images-test\", \"images-val\"]),\n",
    "    image_split_output_mounts=json.dumps([\"/opt/dkube/outputs/train\", \"/opt/dkube/outputs/test\", \"/opt/dkube/outputs/val\"])\t,\n",
    "    \n",
    "    #RNA split\n",
    "    rna_split_script=\"python split.py --datatype rna\",\n",
    "    rna_split_datasets=json.dumps([\"rna\"]),\n",
    "    rna_split_input_mounts=json.dumps([\"/opt/dkube/input\"]),\n",
    "    rna_split_outputs=json.dumps([\"rna-train\", \"rna-test\", \"rna-val\"]),\n",
    "    rna_split_output_mounts=json.dumps([\"/opt/dkube/outputs/train\", \"/opt/dkube/outputs/test\", \"/opt/dkube/outputs/val\"]),\n",
    "    \n",
    "    #Training\n",
    "    job_group = 'default',\n",
    "    #Framework. One of tensorflow, pytorch, sklearn\n",
    "    framework = \"tensorflow\",\n",
    "    #Framework version\n",
    "    version = \"1.14\",\n",
    "    #In notebook DKUBE_USER_ACCESS_TOKEN is automatically picked up from env variable\n",
    "    #By default tf v1.14 image is used here, v1.13 or v1.14 can be used. \n",
    "    #Or any other custom image name can be supplied.\n",
    "    #For custom private images, please input username/password\n",
    "    training_container=json.dumps({'image':'docker.io/ocdr/d3-datascience-tf-cpu:v1.14', 'username':'', 'password': ''}),\n",
    "    #Name of the workspace in dkube. Update accordingly if different name is used while creating a workspace in dkube.\n",
    "    training_program=\"regression\",\n",
    "    #Script to run inside the training container    \n",
    "    training_script=\"python train_nn.py --epochs 5\",\n",
    "    #Input datasets for training. Update accordingly if different name is used while creating dataset in dkube.    \n",
    "    training_datasets=json.dumps([\"clinical-train\", \"clinical-val\", \"images-train\",\n",
    "                                  \"images-val\", \"rna-train\", \"rna-val\"]),\n",
    "    training_input_dataset_mounts=json.dumps([\"/opt/dkube/inputs/train/clinical\", \"/opt/dkube/inputs/val/clinical\",\n",
    "                                      \"/opt/dkube/inputs/train/images\", \"/opt/dkube/inputs/val/images\",\n",
    "                                      \"/opt/dkube/inputs/train/rna\", \"/opt/dkube/inputs/val/rna\"]),\n",
    "    training_outputs=json.dumps([\"regression-model\"]),\n",
    "    training_output_mounts=json.dumps([\"/opt/dkube/output\"]),\n",
    "    #Request gpus as needed. Val 0 means no gpu, then training_container=docker.io/ocdr/dkube-datascience-tf-cpu:v1.12    \n",
    "    training_gpus=0,\n",
    "    #Any envs to be passed to the training program    \n",
    "    training_envs=json.dumps([{\"steps\": 100}]),\n",
    "    \n",
    "    tuning=json.dumps({}),\n",
    "    \n",
    "    #Evaluation\n",
    "    evaluation_script=\"python evaluate.py\",\n",
    "    evaluation_datasets=json.dumps([\"clinical-test\", \"images-test\", \"rna-test\"]),\n",
    "    evaluation_input_dataset_mounts=json.dumps([\"/opt/dkube/inputs/test/clinical\", \"/opt/dkube/inputs/test/images\",\n",
    "                                      \"/opt/dkube/inputs/test/rna\"]),\n",
    "    evaluation_models=json.dumps([\"regression-model\"]),\n",
    "    evaluation_input_model_mounts=json.dumps([\"/opt/dkube/inputs/model\"]),\n",
    "    \n",
    "    #Serving\n",
    "    #Device to be used for serving - dkube mnist example trained on gpu needs gpu for serving else set this param to 'cpu'\n",
    "    serving_device='cpu',\n",
    "    #Serving image\n",
    "    serving_image=json.dumps({'image':'ocdr/tensorflowserver:1.14', 'username':'', 'password': ''}),\n",
    "    #Transformer image\n",
    "    transformer_image=json.dumps({'image':'docker.io/ocdr/d3-datascience-tf-cpu:v1.14', 'username':'', 'password': ''}),\n",
    "    #Script to execute the transformer\n",
    "    transformer_code=\"reg_demo/transformer.py\"):\n",
    "    \n",
    "    create_resource = _component('setup', 'reg-setup')(access_url,\n",
    "                                               auth_token,\n",
    "                                               user)\n",
    "    \n",
    "    clinical_preprocess = _component('preprocess', 'clinical-preprocess')(auth_token, training_container,\n",
    "                                      program=training_program, run_script=clinical_preprocess_script,\n",
    "                                      datasets=clinical_preprocess_datasets, outputs=clinical_preprocess_outputs,\n",
    "                                      input_dataset_mounts=clinical_preprocess_input_mounts, output_mounts=clinical_preprocess_output_mounts).after(create_resource)\n",
    "    image_preprocess  = _component('preprocess', 'images-preprocess')(auth_token, training_container,\n",
    "                                      program=training_program, run_script=image_preprocess_script,\n",
    "                                      datasets=image_preprocess_datasets, outputs=image_preprocess_outputs,\n",
    "                                      input_dataset_mounts=image_preprocess_input_mounts, output_mounts=image_preprocess_output_mounts).after(create_resource)\n",
    "                                      \n",
    "    clinical_split  = _component('preprocess', 'clinical-split')(auth_token, training_container,\n",
    "                                      program=training_program, run_script=clinical_split_script,\n",
    "                                      datasets=clinical_split_datasets, outputs=clinical_split_outputs,\n",
    "                                      input_dataset_mounts=clinical_split_input_mounts,\n",
    "                                      output_mounts=clinical_split_output_mounts).after(clinical_preprocess)\n",
    "                                      \n",
    "    image_split  = _component('preprocess', 'images-split')(auth_token, training_container,\n",
    "                                      program=training_program, run_script=image_split_script,\n",
    "                                      datasets=image_split_datasets, outputs=image_split_outputs,\n",
    "                                      input_dataset_mounts=image_split_input_mounts,\n",
    "                                      output_mounts=image_split_output_mounts).after(image_preprocess)\n",
    "                                      \n",
    "    rna_split  = _component('preprocess', 'rna-split')(auth_token, training_container,\n",
    "                                      program=training_program, run_script=rna_split_script,\n",
    "                                      datasets=rna_split_datasets, outputs=rna_split_outputs,\n",
    "                                      input_dataset_mounts=rna_split_input_mounts, output_mounts=rna_split_output_mounts).after(create_resource)\n",
    "                                      \n",
    "    train       = _component('training', 'regression-model-training')(auth_token, training_container,\n",
    "                                    program=training_program, run_script=training_script,\n",
    "                                    datasets=training_datasets, outputs=training_outputs,\n",
    "                                    input_dataset_mounts=training_input_dataset_mounts,\n",
    "                                    output_mounts=training_output_mounts,\n",
    "                                    ngpus=training_gpus,\n",
    "                                    envs=training_envs,\n",
    "                                    tuning=tuning, job_group=job_group,\n",
    "                                    framework=framework, version=version).after(clinical_split).after(image_split).after(rna_split)\n",
    "    serving     = _component('serving', 'model-serving')(auth_token, train.outputs['artifact'], device=serving_device,\n",
    "                                serving_image=serving_image,\n",
    "                                transformer_image=transformer_image,\n",
    "                                transformer_project=training_program,\n",
    "                                transformer_code=transformer_code).after(train)\n",
    "    inference   = _component('viewer', 'model-inference')(auth_token, serving.outputs['servingurl'],\n",
    "                                 'regression', viewtype='inference').after(serving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and generate tar ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"0\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(d3pipeline, 'dkube_regression_pl_full.tar.gz')\n",
    "# Upload this generated tarball into the Pipelines UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
